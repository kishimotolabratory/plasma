{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4単純なレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 乗算,加算レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy\n",
    "\n",
    "\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from layer_naive import *\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.51　RELUレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1.0,-0.5], [-2.0,3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (x <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(20).reshape(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68186123, -0.32355821,  1.93456136, -0.67578826],\n",
       "       [ 0.59308972, -0.34038686,  1.73767686,  0.31745233],\n",
       "       [ 1.66037327, -1.07196106,  0.86006492,  0.32159425],\n",
       "       [ 1.10787101, -0.35721309, -0.29051464,  0.87697335],\n",
       "       [ 0.65222822, -1.54241674,  0.03614391,  0.76581379]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False],\n",
       "       [ True, False,  True,  True],\n",
       "       [ True, False,  True,  True],\n",
       "       [ True, False, False,  True],\n",
       "       [ True, False,  True,  True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mask  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[mask] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2  シグモイドレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.61Affineレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 重み・バイアスパラメータの微分\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # テンソル対応\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 入力データの形状に戻す（テンソル対応）\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmaxの出力\n",
    "        self.t = None # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 教師データがone-hot-vectorの場合\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差伝播法の実装 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークの実装 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.7.3誤差電波法の勾配確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 誤差伝播法のメリットは直接微分を行わず、解析的に数式を解いて勾配を求めるため、効率的に早く計算が可能。\n",
    "* 数値微分は勾配確認として複雑で実装ミスが起きやすい誤差伝播法の正しさを確認するために用いられる。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7.4誤差伝播法を使った学習 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12211666666666667 0.1242\n",
      "0.9001 0.9046\n",
      "0.9243833333333333 0.9277\n",
      "0.9361166666666667 0.9363\n",
      "0.94575 0.9454\n",
      "0.9521333333333334 0.9513\n",
      "0.9574166666666667 0.9532\n",
      "0.96095 0.956\n",
      "0.9656833333333333 0.9586\n",
      "0.9679166666666666 0.9613\n",
      "0.9699833333333333 0.9642\n",
      "0.9708333333333333 0.964\n",
      "0.9745 0.9657\n",
      "0.9742333333333333 0.9657\n",
      "0.9767166666666667 0.9675\n",
      "0.9778666666666667 0.9682\n",
      "0.9781833333333333 0.97\n",
      "CPU times: user 47.5 s, sys: 9.05 s, total: 56.5 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配法でしてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc2, test acc2 | 0.11016666666666666, 0.1109\n",
      "train acc2, test acc2 | 0.9049666666666667, 0.9105\n",
      "train acc2, test acc2 | 0.9239, 0.9264\n",
      "train acc2, test acc2 | 0.93635, 0.9357\n",
      "train acc2, test acc2 | 0.9443, 0.9429\n",
      "train acc2, test acc2 | 0.9481, 0.9431\n",
      "train acc2, test acc2 | 0.9551333333333333, 0.9521\n",
      "train acc2, test acc2 | 0.95985, 0.9557\n",
      "train acc2, test acc2 | 0.9629333333333333, 0.9574\n",
      "train acc2, test acc2 | 0.9663166666666667, 0.9601\n",
      "train acc2, test acc2 | 0.9682833333333334, 0.9616\n",
      "train acc2, test acc2 | 0.9711166666666666, 0.9623\n",
      "train acc2, test acc2 | 0.9722166666666666, 0.964\n",
      "train acc2, test acc2 | 0.9732666666666666, 0.9629\n",
      "train acc2, test acc2 | 0.9754, 0.9662\n",
      "train acc2, test acc2 | 0.9775, 0.9688\n",
      "train acc2, test acc2 | 0.9784166666666667, 0.9672\n",
      "CPU times: user 53.9 s, sys: 9.7 s, total: 1min 3s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000  # 繰り返しの回数を適宜設定する\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list2 = []\n",
    "train_acc_list2 = []\n",
    "test_acc_list2 = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list2.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list2.append(train_acc)\n",
    "        test_acc_list2.append(test_acc)\n",
    "        print(\"train acc2, test acc2 | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 100  # 繰り返しの回数を適宜設定する\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 20\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc2, test acc2 | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (17,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5888a2ae8bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc_list2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3259\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3260\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 243\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (17,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAElCAYAAAC/A3VYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8XFX9//HXZ7JvTbN0oRstFJCytVD2rQpUCsqqLIIgCuhXcfsKP0BlETcEcUcU/SLIKossaoEKNoLIVqAsbYEWKDRt6ZImbZZmm3x+f9ybdJJmmbSZzCTzfj4e88jMPefe+7k309NPzr33HHN3RERERCS1RJIdgIiIiIhsTUmaiIiISApSkiYiIiKSgpSkiYiIiKQgJWkiIiIiKUhJmoiIiEgKUpKWBsxsuZkd3UPZ4Wb2Vi/r3mpmP+il3M1s6kDEGQ8zO8vM5g3W/kRERJJFSVqac/en3X23ZMcRL3e/091nJzsOADO72sxazKwu5rVTTPl0M3vJzBrCn9OTGa+IiAwtStJEts9f3L0w5vUugJllAw8DdwAlwG3Aw+FyERGRPilJSx/Tzew1M9toZn8xs1wAM5tlZpXtlcxshpm9bGa1ZvYXIDd2I2Z2iZmtNrNVZvb5LmU5ZvZTM/vAzNaY2e/MLC92P2b2LTNbG27jvJ6CNbPPmdm7YRzvmdlZMcv/E77/f116sVrM7NawrNjM/i/cz0oz+4GZZQzMqYzLLCAT+IW7N7n7rwADPjaIMYiIyBCmJC19nAYcC0wB9gY+17VC2MvzEHA7UArcB5waU34scDFwDLAL0PU+t58AuwLTganAeODKmPKxQHG4/AvAjWZW0k0cBcCvgDnuXgQcAizsWs/dr2vvwQJ2B9YB94bFtwGtYRwzgNnA+d2dGDP7jJnV9PKa1N16oU+a2QYzW2Rm/xOzfA/gNe8879pr4XIREZE+KUlLH79y91XuvgH4G0Ei1dVBQBZB70+Lu98PvBhTfhrwJ3d/w93rgavbC8zMgAuAb7r7BnevBX4EnBGzfgtwTbjtuUAd0NP9cG3AnmaW5+6r3X1RTwcW9tY9BPzS3eea2RhgDvANd69397XAz7vE0sHd73L3kb28Puhh1/cSJIejwmO/0szODMsKgY1d6m8Eino6DhERkVhK0tLHhzHvGwiSiK7GASu79P6836V8RQ9lo4B84KX2HijgsXB5uyp3b+0rjjABPB34ErDazP5hZh/p8cjg/4C33P0n4ecdCZLN1TGx/B4Y3cs2+s3dF4eJb9Td/wv8EvhUWFwHjOiyygigdiBjEBGR4UtJmsRaDYwPe8XaTepSPrGHsvXAZmCPmB6o4vBSZL+5++PufgywA/Am8Ifu6pnZZQS9cV+IWbwCaALKY2IZ4e7dXmoMh/Wo6+XV2+XOTmET3HcGsAjYu8u53DtcLiIi0iclaRLrWYL7uL5mZplmdgpwQEz5vcDnzGyameUDV7UXuHsbQSL1czMbDWBm483s4/0NwszGmNkJ4b1pTQS9UtFu6s0Bvgac5O6bY2JZDcwDbjCzEWYWMbOdzezI7vYXDutR2Mur28udZnaimZVY4IAwlofD4oow5q+FD1RcFC7/V3/Ph4iIpCcladLB3ZuBUwgeKqgmuOT415jyR4FfECQay9g64bg0XP6cmW0CnqDne856EwG+BawCNgBHAl/upt7pBJdTl8T0ev0uLDsHyAYWh8dyP0Gv3EA6g+B4a4E/Az9x99ug41yeFMZRA3yeIJlsHuAYRERkmLLOtx+JiIiISCpQT5qIiIhIClKSJiIiIpKClKSJiIiIpCAlaSIiIiIpSEnaMGNmt5rZD3op/7aZ/XEwYxIREZH+U5I2yMxsuZl1nfNywOp3WbfT5OkA7v4jd+92DsuBFsa+OWZ4jHkxZWeY2VsWTPi+1sxuM7OuI/SnLDM7yszeNLMGM5tvZjv2Y93zzWxZeE4eM7NxMWWPdhlIt9nMXo8pnxzuryHc/9ExZUP6nIqISGdK0iTRPhkzKOzsmOXPAIe6ezGwE5AJ9NgDmErMrJxg/LgrCCaiXwD8Jc51jySY0/TEcN33gLvby919TuxAusB/CSa6b3c38ApQBnwHuN/M2qfeGrLnVEREtqYkbRCZ2e0EUyn9Lewl+X/h8hPMbFE4z2SFme3eR/37zOzDsMfkKTPbarqjcLT+R4FxMb0y48zsajO7I6wz2czczM4zsxVmVm1mXzKz/c3stTCe33TZ7ufNbElY9/H+9CDFcvcV7r4+ZlEUmBqzn0vNbKWZ1Ya9Q0fFs10zu8zM3gnXW2xmJ3cpvyCMv71833C5m1ns/nu7bHwKsMjd73P3RoKJ5vex3ucXbfdJ4D53XxQObPt94Agz27mbY5kMHA7cHn7eFdgXuMrdN7v7A8DrwKnQ9zkVEZGhRUnaIHL3zwIfsKV36brwP967gW8QjJ4/lyApy+6ufripR4FdCCYMfxm4s5t91QNzgFUxPTOregjtwHB7pxPMKPAd4GhgD+C0sPcHMzsJ+DZBkjIKeJqYXiAz+7sFc2nGutPM1pnZPDPbJ7bAzA4zs40EI/afGu4bM9sNuAjY392LgI8Dy3uIvat3CBKbYuB7wB1mtkO43U8TJFTnEEx2fgJQFc9Gw4T1sPDjHsCr7WXhuX4nXN7nptgyvycx7/fspu45wNPu/l7Mft9199hJ2l+N3W9P51RERIYeJWnJdzrwD3f/p7u3AD8F8oBDelrB3W9x91p3b2JLL07xdsTwfXdvdPd5QD1wt7uvdfeVBInYjLDeF4Efu/sSd28luGw3vb03zd0/4e7Xxmz3LGAysCMwH3jczEbGHMd/wktzE4Dr2ZKIRYEcYJqZZbn7cnd/J54DCXu3Vrl7m7v/BVjKlvlHzweuc/cXPbDM3d+Pc7sj3f0/4cdCYGOXKhuBojg2NZcg8d3bzPKAKwkmZs/vpu45wK0xn/vcby/nVEREhhglack3DuhIFMKJylcA47urbGYZZnZteElvE1v+Ey7fjhjWxLzf3M3nwvD9jsAvw16lGoJ5Na2nWN39mfCyXIO7/5hgDsvDu6m3EngMuCf8vIygZ/FqYK2Z3RN7c31vzOwcM1sYE+OebDk3Ewl6vLZXHUFPXKwRBL1XvXL3Jwkmpn+A4Pe+PFyv0wMeYa/dWII5R/u9367nVEREhh4laYOv62SpqwiSHwDMzAiSiZU91P8MwU3nRxNc0pvcvmoc+9peK4Avhr1K7a88d/9vnOs73ccJwU3uHfdluftd7n4Ywblx4Cd9bTzs0fsDwaXSMncfCbwRs88VsfvoooHOvVlje9nVIqDj0m14/9/O4fI+ufuN7r6Lu48mSNYywzhjnQv81d3ruux3JzOL7bHbp5f9djqnIiIytChJG3xrCJ68a3cvcLwFQzpkAd8Cmgie6uuuflFYXkWQVPyoj32Vbeel0Fi/Ay5vf1DBzIrD+7y2YmaTzOxQM8s2s1wzu4SgR+uZsPyssI6FydUPgSfDst3M7GNmlgM0EvTmRcOyWWbWU/JZQJDQrQvrnkfne73+CFxsZvuF+50a8+DDQuAzYU/lscCRvZyHB4E9zexUM8sluGT5mru/Ge73ajOr6OG85JrZnuH+JwE3A7909+qYOnnAp+l8qRN3fzuM86pwOycDexMker2eUxERGXqUpA2+HwPfDS/HXezubwFnA78G1hM8/ffJ8Mm/reoDfya4TLYSWAw819OOwqThbuDdcP24Lhn2sr0HCXq07gkvtb5B8HAC0DHG17fDj0XATUB1GOuxwBx3b79RfxpBIlpHkLi9BVwQluUA1xKcjw8JHpBo3+5E4Nke4lsM3BCWrwH2CrfdXn4fQeJyF8ElwocIhsEA+DrBua8huJfuodhtW/B07OHhdtYR3JT/w/D4DgTOiKk+MXa/Fjy5e1b4MTfcfx3wQhjrFV0O5SSCe83md3OYZwAzw/1eC3wqjAd6P6ciIjLEmPtAXxETSRwLZku4z90fT3YsPTGzhcBRMQmpiIhIvylJExEREUlBCbvcaWa3WDA1TdcbotvLzcx+ZcH0OK9ZOKioiEgqUBsmIsmWyHvSbiW4D6kncwgGUN0FuJDg/iURkVRxK2rDRCSJEpakuftTBONo9eRE4M/hoKLPASPbR4YXEUk2tWEikmyZSdz3eIJxq9pVhstWd61oZhcS/KVKXl7efhMnTox7J21tbUQiqfMQq+LpneLpXbrG8/bbb69391F91xxUcbVhse1XQUHBfh/5SDxTvIrIcPHSSy9tc/uVzCQt7sFX3f1mgvGkmDlzpi9YsCDunVRUVDBr1qxtiS8hFE/vFE/v0jUeM4tr+q5BFlcbtj3tl4gMfdvTfiXzT/JKgvGk2k0gGH1fRGQoUBsmIgmVzCTtEeCc8Ampg4CN7r7VpU4RkRSlNkxEEiphlzvN7G5gFlBuZpUEk0pnAbj774C5wHHAMoJ5E89LVCwi6aqtzWlqbaOxJcrmlminn40tbWxujtLU2kZrWxutUQ9+tnn43om2tdESdaJtTms0LAvLo21trKhs4p/Vr+OAO7h78JP2nzHL2fIzPzuDH5+yd3JPTh/UholIsiUsSXP3M/sod+Aridq/yGByDxOZNqfNnebWNmobW6ltbKWuqZW6ppYt78OfW8pbOi1vn4XezMKfYBhmUF+/mcJXn96yPKasJeph8tU5ERtIWRlGRsTIikSIRIy21layN3wYxrJ1vB3H0SXWEblZAxpXIqgNE5FkS+aDAyLbpCXa1tE71NgSjXnfRlNrlKaWtk7Lm1q3LO9439oWfm4v775OXf1msv77JFF32tqTsDYnGiZl0fB9fyfuiBgU5mRSlJtFYU4mhbmZjMzPZkJJfpDZxPZGxbxf19ZA2cg86NRTFfROZUYi5GVnkJdp5GZnkpeVwQirp8iayM9oJT8SJT8jSmZmFtHRe5CbGaG8agG5zRvIsDYycSLmRPJKiE49hsxIhJy3HyGjcQMZtGEexbwNisfDHicDsOz2bzJ1h2JobYZoE7Q2wdi94cALgwO991xoqIJoc1AWbYZdj4WjrxrAb4SIyPCkJE0GnbvT0ByluqGZmoYWNm5uoaahheqGZl55p5ln6hdT09BCzeYWasI6NZtbaGhqpbG1jWhbf6cyc3JoIY8mCq2JkqwW1meMxrMKmJhRxXTepjDSTGGkiQJrpsCa+E/JSTTmjqJ85UJmZ74EHb1EhlmEp8efT2NOGTvVvsiu1U+BGRHAIkH5wqlfIbdwJFPXP8GE1U+QZa1keQuZ3kKmtxI550EsKxee+im8cgdsboG6MInB4LLwYaC5/w9eu6fjSFpaW8myUvhmOAj+Q1+BN/8WZGttrUGiVDgW/ndRUH77KfDOk51PR/lucNELwfv5N8CK5zuXj98Ppn8ieP/sz2BNlwH3pxzZkaSNXzkX3lsPmbmQkQ2ZOWAxt7o210FbFLLyILc4qFOkocREROKhJE36pTXaRnWYWMVeogvet1DfHO24hFff1Pl9cIkvWLcl2p5oOVlEyaOJXJrJsyZGLn+P5rxRUDCK8TmNzM57jZEjWiiMtJBPE7k0UTnmYzSU7s6ozcvZ652byGprIiu6mcy2RjKjm1l76DVEdzyM4sp/UfrI5zCPdj6Qc/4OUw6H1++HB67vcpTGJ087H8bPYMk9D7J7ZZjQuNM+wsLMI6+C0inw/NOw/Imtyvc64xooHA3PboalbwbJSfsrMwc8vAw5YjxMmAkZOZCRFZTHJjkTDwiuE4bWVFYyYfLOW8p3PARyCoP3kcxg/bySLeUHfgmmnRjss33fuSO3lJ/42yCxswyIZAT7zsqLOU8PB7FaJHhFMiCy5VLl8wfexKyPfqz7LwvA2Q/0XCYiIr1SkpbG3J3Nrc77VfVsqG+muqGZqrrg54b6FjbUN7GhvoVo7RoaGhpoaGigqWkzObRQTSGVPpoIbZwYeYZ8C5KnfJoojTSzKmsPFuYeyKjsJr69+WfkW1OQiGU2kVvYyBuTPsuqXT/L2LbVHPHoMVsHd9T1cOApsGYR3PSprYoP3HcGTJ8Mq2pg8bthT00BZJVBVh47ji2HUYVg0+Cwb0J2PmQVhD/zYdRuwYamHgVffi5Yll0YlGfmdiRGa8Z+jN3PuKbnk3jghVsu7XXn4C8Hr55MPzN49WSvTwWv0LKKCibEjks24yzgrJ7X33V2z2UA5VN7Ly8o773cUmdgXRGR4UZJ2jDUEm1jfW0j6+qaWbupibYPniNa/QHR2rVEGtaR3VjFW61j+eXm42iOtvHXp45gjFUzkRayaSGHVh71A/lx7jcpLcjhoZrzyPGmYOM5wY/3Jp/Gewf9gMKsCAfcfnbnADKy4ZBd4KiPQnM93PJDyN6SQJFdwGHTpsNHJkJjMTR9N0igsvJYsux9dt97Xxi7V7Ct0p3hy89DVm6QSLW/2ke5HzcdLnqx55NRPhWOuqLn8rySzj1PIiIiKUJJ2hC0sbaOlStXsLRxBO+tr2fy0tsor11CXnMVha01lHgNy9vGcWbLdwGYl305u0ZWAtBKBpsiIykYcTDn7TuZmjWVjLADMGvCc3IhJw/y8jlxwgxO2vPoYIcvXR/0LGXkQGY2ZOYyZeSOTBkzJij/2iudE6iMmK9VdgF86emeDyZ3BBxxScfHNXUV7D5t1pbyrFwYrWl0REQk/ShJS1H1tRtZXgvL1zeQseRBilf/l4KGDxjVvJIxXkWRl/P15l9iBn/KfYFd7H3qs0pozBvPmvx9yCrZlZv32o/RI3IZufk2mkcUkj1iDJm5IymNRDgYOBioqFjD1Fk39R7Mfuf2Xl6600AdtoiIiISUpCVLWxTHWFfXzMrXK2hb+gSRmuUU1K+gvGUVBd7AJ5tupY0IP8x8ggMyX2R91jg+HDmDlSMnkz16V+btdwSTSvPJzTq+j53tPyiHJCIiIgNHSVqitA+cZQZrl9C8eC6bVi9l4geLqHp2A8VNHzLHfsvSzYVclPEg38y8nzVWzvrscbxdciRtIydz4957MWlMCZNLjqYgL4fS5B6RiIiIDCIlaQOlYQMseQR/ex7N698lY+P73Lv7jVTUT2Jy5cN8u/lXmBdR66N42ybSkH8wR04Zy1njJ7F72d5sGvcLxo0oZFyyj0NERERSgpK0AdD6wQtEbj2OSFsLK30Ub7ZNYIUfzh0vbYCyUgomHstNo09l5wljqXl/MZ869qNEItb3hkVERCRtKUnrr9ZmWPYE/sb9rMmbyu/bTuTRhes5p3kOz2QfypS9DmH6pFL2H1vEmaMLyc3K6LR6xbo3laCJiIhIn5SkxWv5M/DaPbQteoRIUw2brIg7miPcyQccPW0Mu874KRfsNoqsDA3uKSIiIttPSVpP3GHtYhizB/VNrdQ8/jNKP3yGx1r34+HowTRMOIIT99uRF/caR3F+Vt/bExEREekHJWndef1+/F/fx6qX88Opd3Hn2xkUNZ9EUcn5HL/vzlw9YzyTywuSHaWIiIgMY0rSulH1r1/TWl3LT1su5KllLZw4fSKn7HsAM3cswUz3k4mIiEjiKUnrRvOmNbwemcas0/+X7+8+equb/0VEREQSTUlaN4qiG8kpGc3svXdIdigiIiKSpvQoYlfu/NLP4L1RH0t2JCIiIpLGlKR10djaxh+ajqZ+h4OSHYqIiIikMSVpXVRvqGJXW8Ho3LZkhyIiIiJpTElaF43vPsu8nEvZseXdZIciIiIiaUxJWhebN34IQH7p2CRHIiIiIulMSVoXrZvWAjCiTEmaiIiIJI+StC7aatfS5FmUlpQlOxQRERFJY0rSuohsrqKKERTkaAg5ERERSR5lIl1UFB7Pmo178ENN/yQiIiJJpCSti5d9FzYU75jsMERERCTNKUnrYofqlygvGp/sMERERCTN6Z60WO5ctelKjm/8R7IjERERkTSnJC2GN9eRSzOeX57sUERERCTNKUmL0VC9BgArHJXkSERERCTdKUmLsalqNQDZRaOTHImIiIikOyVpMeo3BFNC5Ywck+RIREREJN0pSYtRmT+N85ovIW/sR5IdioiIiKS5hCZpZnasmb1lZsvM7LJuyieZ2Xwze8XMXjOz4xIZT18+jBYxv20GJaWlyQxDRFLAUGu/RGT4SViSZmYZwI3AHGAacKaZTetS7bvAve4+AzgD+G2i4olH5uqXOCLyKqUF2ckMQ0SSbCi2XyIy/CSyJ+0AYJm7v+vuzcA9wIld6jgwInxfDKxKYDx92vX9u/hh1q3kZmUkMwwRSb4h136JyPCTyBkHxgMrYj5XAgd2qXM1MM/MvgoUAEd3tyEzuxC4EGDMmDFUVFTEHURdXV3c9Us3fUiNjeCdfmy/v/oTz2BQPL1TPL1LtXgGUELar0mTJg14oCIyfCUySetuhnLv8vlM4FZ3v8HMDgZuN7M93b2t00ruNwM3A8ycOdNnzZoVdxAVFRXEW//9Z+pYmz0q7vrboj/xDAbF0zvF07tUi2cAJaz9Ski0IjIsJfJyZyUwMebzBLa+HPAF4F4Ad38WyAWSNtx/YWsNjTl6aEBEhl77JSLDTyKTtBeBXcxsipllE9xY+0iXOh8ARwGY2e4Ejdy6BMbUM3eKfSOtuWVJ2b2IpJSh1X6JyLCUsCTN3VuBi4DHgSUET0EtMrNrzOyEsNq3gAvM7FXgbuBz7p6UywFtbW2c1PIDlk78dDJ2LyIpZKi1XyIyPCXynjTcfS4wt8uyK2PeLwYOTWQM8drYGOWN6I6cWrZjskMRkRQwlNovERmeNONAaOOH73BWxhOMzaxNdigiIiIiStLaNX/wEj/MuoWxkY3JDkVERERESVq75k3B/b5FpZpcXURERJJPSVqoddMaAIrLdkhyJCIiIiJK0raoX0+NF1BSVJDsSERERESUpLXLaKyixkaQmaFTIiIiIsmX0CE4hpJbS77Gmta13JHsQERERERQktZhRWMuVqTJj0VERCQ16Npe6ONVd3BwZHGywxAREREB1JMWaItyXvOd/DualexIRERERAD1pAHQUreeCA755ckORURERARQkgbApvWrAMgoGp3kSEREREQCStKA2g3BQLY5xUrSREREJDUoSQMaqz8EIK9Esw2IiIhIalCSBrxVfjR7N/6BgnG7JTsUEREREUBJGgDr61vYRAFlRfnJDkVEREQEUJIGwNj3HuSrmQ8zIldDcIiIiEhq0DhpwI7r5rNb5nIiEUt2KCIiIiKAetIAyGnaQF3myGSHISIiItJBSRqQ31pNY1ZJssMQERER6aAkDRgRraE5tyzZYYiIiIh0UJIWbSHDW4nmaUooERERSR1pn6Q1tkWY1vQnFk+9INmhiIiIiHRI+yStqr4ZgPKi3CRHIiIiIrJF2idpDcsX8POsGxnva5MdioiIiEiHtE/SWj58k5MznqE0L+1PhYiIiKSQtM9MmjetAaCoTJOri4iISOpI+yTN69bR7BmUlurpThEREUkdaZ+kWcN6NlBMfo5myBIREZHUkfZJ2uZWY1VkB8w0b6eIiIikjrTvPvrdiK9Rk9nMw8kORERERCRG2vekVdU3UVqQnewwRERERDpJ+yTtOxuuYHbr/GSHISIiItJJWidp3lTHwf4KYyM1yQ5FREREpJOEJmlmdqyZvWVmy8zssh7qnGZmi81skZndlch4uqqvDsZIixSMGszdisgQkOrtl4gMfwl7cMDMMoAbgWOASuBFM3vE3RfH1NkFuBw41N2rzWx0ouLpzqaq1RQCWSMGdbcikuKGQvslIsNfInvSDgCWufu77t4M3AOc2KXOBcCN7l4N4D64E2g2VK8GIKdYbauIdJLy7ZeIDH+JHIJjPLAi5nMlcGCXOrsCmNkzQAZwtbs/1nVDZnYhcCHAmDFjqKioiDuIurq6HutXvfMerW0TeXdVFbX92Ob26C2eZFA8vVM8vUu1eAZQQtqvSZMmJSRYERmeEpmkdTc6rHez/12AWcAE4Gkz29PdO93J7+43AzcDzJw502fNmhV3EBUVFfRU/668nTh26R48O/tj7FCcF/c2t0dv8SSD4umd4uldqsUzgBLWfg18qCIyXMV1udPMHjCz482sP5dHK4GJMZ8nAKu6qfOwu7e4+3vAWwSN3qDYUN8EoHHSRKSrlG+/RGT4izfpugn4DLDUzK41s4/Esc6LwC5mNsXMsoEzgEe61HkI+CiAmZUTXD54N86Yttv0t37Ozbm/IiczY7B2KSJDQ8q3XyIy/MWVpLn7E+5+FrAvsBz4p5n918zOM7OsHtZpBS4CHgeWAPe6+yIzu8bMTgirPQ5UmdliYD5wibtXbd8hxa+09m0mRgZtdyIyRAyF9ktEhr+470kzszLgbOCzwCvAncBhwLkE92Rsxd3nAnO7LLsy5r0D/xu+Bl1eSzVVmaXJ2LWIpLhUb79EZPiLK0kzs78CHwFuBz7p7qvDor+Y2YJEBZdoha3VrCrYOdlhiIiIiGwl3p6037j7v7orcPeZAxjP4HGn2DfSmleW7EhEREREthLvgwO7m9nI9g9mVmJmX05QTIOiraWRZ9umUT9yt2SHIiIiIrKVeJO0C2LH/glH2L4gMSENjpqWDM5tvoy1k7sOIi4iIiKSfPEmaREz6xjcMZzXbkgPLlZVF46RVpiT5EhEREREthZvkvY4cK+ZHWVmHwPuBraa/mQoaX3zMZ7O/joTW1f0XVlERERkkMX74MClwBeB/yGYLmUe8MdEBTUYWmpWMjGyjubikX1XFhERERlkcSVp7t5GMOvATYkNZ/BEa9cCUFy+Q5IjEREREdlavOOk7QL8GJgG5LYvd/edEhRXwnn9ejZ5PiUjipIdioiIiMhW4r0n7U8EvWitBHPV/ZlgYNshK2PzeqqtmIyI9V1ZREREZJDFm6TlufuTgLn7++5+NfCxxIWVeMsypvJc9kHJDkNERESkW/E+ONBoZhFgqZldBKwERicurMS7J+skMsqN05MdiIiIiEg34u1J+waQD3wN2I9govVzExXUYKiqa6JMY6SJiIhIiuqzJy0cuPY0d78EqAPOS3hUidbWxty6T/N03fnAvsmORkRERGQrffakuXsU2C92xoGhrrmuilxayMotSHYoIiIiIt2K9560V4AMzIG6AAAbyklEQVSHzew+oL59obv/NSFRJdimqtWUAxlFo5IdioiIiEi34k3SSoEqOj/R6cCQTNJqwyQtp3hMskMRERER6Va8Mw4M/fvQYjTWfAhAfsnYJEciIiIi0r14Zxz4E0HPWSfu/vkBj2gQrImM5qXWozisfGKyQxERERHpVryXO/8e8z4XOBlYNfDhDI5lWbvxg9Yv8GqZLneKiIhIaor3cucDsZ/N7G7giYRENAg2bdpIdsQZkRdvjioiIiIyuLY1S9kFmDSQgQymo9+6ipNy3sHsE8kORURERKRb8d6TVkvne9I+BC5NSESDIKepmrqMkckOQ0RERKRH8V7uLEp0IIMpv7WamuwpyQ5DREREpEdxzd1pZiebWXHM55FmdlLiwkqsEdFqmnNKkx2GiIiISI/inWD9Knff2P7B3WuAqxITUoJFWyimjrb88mRHIiIiItKjeJO07uoNyUcjGxob+WnLp9kw+qBkhyIiIiLSo3iTtAVm9jMz29nMdjKznwMvJTKwRKlqyuA30ZNpGa8kTURERFJXvEnaV4Fm4C/AvcBm4CuJCiqRaqo3MIYNlOVnJDsUERERkR7F+3RnPXBZgmMZFJGlj/F87rdY0vYkMC7Z4YiIiIh0K96nO/9pZiNjPpeY2eOJCytxmjetBWBE2Q5JjkRERESkZ/Fe7iwPn+gEwN2rgdGJCSmxvG4tLZ5BSdmoZIciIiIi0qN4k7Q2M+uYBsrMJtN5BoIhwxqqqKGI/JzsZIciIiIi0qN4h9H4DvAfM/t3+PkI4MLEhJRYWY1VbIyMRP1oIiIiksrifXDgMTObSZCYLQQeJnjCc8h5PG8ObrVcnOxARERERHoR74MD5wNPAt8KX7cDV8ex3rFm9paZLTOzHp8ONbNPmZmHiWBC/Ss6ncVlxyR6NyIyxKVi+yUi6SXee9K+DuwPvO/uHwVmAOt6W8HMMoAbgTnANOBMM5vWTb0i4GvA8/2Ie5uN3rSIiTkNg7ErERmiUrX9EpH0Em+S1ujujQBmluPubwK79bHOAcAyd3/X3ZuBe4ATu6n3feA6oDHOWLaZNzfwp9ZL+Vj9o4nelYgMbSnXfolI+on3wYHKcJy0h4B/mlk1sKqPdcYDK2K3ARwYW8HMZgAT3f3vZtbjbWJmdiHhgwpjxoyhoqIizrChrq6uo360bi1HAesbvF/bGEix8aQCxdM7xdO7VItnACWk/Zo0aVJP1UREthLvgwMnh2+vNrP5QDHwWB+rWXeb6ig0iwA/Bz4Xx/5vBm4GmDlzps+aNavvoEMVFRW011+5+FlYAOOm7sHB/djGQIqNJxUont4pnt6lWjwDKGHt1wDFJyJpIN6etA7u/u++awHBX54TYz5PoHPvWxGwJ1BhZgBjgUfM7AR3X9DfuOJRv2E1ADkjxyZi8yIyfKRc+yUi6Sfee9K2xYvALmY2xcyygTOAR9oL3X2ju5e7+2R3nww8ByS0gWusWQNAQYmSNBHpVcq1XyKSfhKWpLl7K3AR8DiwBLjX3ReZ2TVmdkKi9tubdwv25hvNX6Z4tO4LEZGepWL7JSLpp9+XO/vD3ecCc7ssu7KHurMSGQvAB22jeajtMK4rHpHoXYnIEJdq7ZeIpJ+EJmmpJmfdaxyc+yHZmYm8yisiIiKy/dIqSTvsg99zZKQK+EqyQxERERHpVVp1KeW2VNOQOTLZYYiIiIj0Ka2StMLWahpzSpMdhoiIiEif0idJc6fYN9KaW57sSERERET6lDZJWrSpjlyaIb8s2aGIiIiI9CltkrSaJjiz+TusnXhsskMRERER6VPaJGlVjfBs2x7kjNop2aGIiIiI9CltkrTa1cv4RORZRuU0JzsUERERkT6lTZKW8f7T/Cb714zObEx2KCIiIiJ9SpskLVq7FoDiMk2uLiIiIqkvbZI06tdR63mMLC5OdiQiIiIifUqbJC1jcxUbbQQZEUt2KCIiIiJ9SpskLbupik0ZmhJKREREhoa0mWD91wVfI7+whRuSHYiIiIhIHNKmJ+3NxhKaSqYmOwwRERGRuKRHktbWxnF1D7BnZHmyIxERERGJS1okac311VzCn5nW/HqyQxERERGJS1okaRvXrwIgo2hUkiMRERERiU9aJGm1VasByB4xJsmRiIiIiMQnLZK0zTVrAMgvUZImIiIiQ0NaJGktm4IkrahsXJIjEREREYlPWiRpr5Qez2FNv6S4XEmaiIiIDA1pkaSt2WysiYxmRH5OskMRERERiUtaJGmTKx/mvNynMNO8nSIiIjI0pMW0UNPX/509LZrsMERERETilhY9afmtNWzOKkl2GCIiIiJxS4skrShaQ3NOabLDEBEREYnbsE/SrC1KsdcSzStPdigiIiIicRv2SVpb4yYi5liBkjQREREZOoZ9kraeYnZp/DNrdjk92aGIiIiIxG3YJ2mbmp0WMiktLkp2KCIiIiJxG/ZDcBTWLOHqzH8zKmP3ZIciIiIiErdh35M2ou4dPpc5j9L8rGSHIiIiIhK3hCZpZnasmb1lZsvM7LJuyv/XzBab2Wtm9qSZ7TjQMWQ2byTqRkn5mIHetIgMY6nQfolIektYkmZmGcCNwBxgGnCmmU3rUu0VYKa77w3cD1w30HHktGykmhHk52QP9KZFZJhKlfZLRNJbInvSDgCWufu77t4M3AOcGFvB3ee7e0P48TlgwkAHkde6kY2R4oHerIgMbynRfolIekvkgwPjgRUxnyuBA3up/wXg0e4KzOxC4EKAMWPGUFFREXcQedEWqinu1zqJVFdXlzKxgOLpi+LpXarFM4AS0n5NmjRpoOITkTSQyCTNulnm3VY0OxuYCRzZXbm73wzcDDBz5kyfNWtW3EEc8cxl7DKujP+bdUDc6yRSRUUF/Yk/0RRP7xRP71ItngGUsPZroAIUkeEvkUlaJTAx5vMEYFXXSmZ2NPAd4Eh3bxroIDY1O2VFOQO9WREZ3lKi/RKR9JbIe9JeBHYxsylmlg2cATwSW8HMZgC/B05w97UDHYC3NvGTtp+xf8uCgd60iAxvSW+/REQSlqS5eytwEfA4sAS4190Xmdk1ZnZCWO16oBC4z8wWmtkjPWxum9RWreHjGS8y1jYM5GZFZJhLhfZLRCShMw64+1xgbpdlV8a8PzqR+99UtYoRQPaI0YncjYgMQ8luv0REhvW0UPXVqwHIKdZAtjJ4WlpaqKyspLGxccC3XVxczJIlSwZ8u9tqoOPJzc1lwoQJZGVphhARkWGdpDXWBLeJFJSOTXIkkk4qKyspKipi8uTJmHX3kOC2q62tpaioaEC3uT0GMh53p6qqisrKSqZMmTIg2xQRGcqG9dyddY0trPZSisvHJTsUSSONjY2UlZUNeII23JkZZWVlCemBFBEZioZ1T9qC4o9zVtMU3i4pT3YokmaUoG0bnTcRkS2GdU9aVX0TBVmQnTmsD1NERESGoWGdvRy5/BdckfHnZIchMqhqamr47W9/u03rHnfccdTU1AxwRCIisi2GdZK2Y91r7BxZnewwRAZVb0laNBrtdd25c+cycuTIRIQlIiL9NKzvSStoraYyc7dkhyFp7Ht/W8TiVZsGbHvRaJS9JpZw1Sf36LHOZZddxjvvvMP06dM55phjOP744/ne977HDjvswMKFC1m8eDEnnXQSK1asoLGxka9//etceOGFAEyePJkFCxZQV1fHnDlzOOyww/jvf//L+PHjefjhh8nLy+u0r0cffZQbbriB5uZmysrKuPPOOxkzZgx1dXV89atfZcGCBZgZV111FaeeeiqPPfYY3/72t4lGo5SXl/Pkk08O2LkRERluhnWSNtI30phZnOwwRAbVtddeyxtvvMHChQuBYBL0F154gTfeeKNjaItbbrmF0tJSNm/ezP7778+pp55KWVlZp+0sXbqUu+++mz/84Q+cdtppPPDAA5x99tmd6hx00EE899xzmBl//OMfue6667jhhhv4/ve/T3FxMa+//joA1dXVrFu3jgsuuICnnnqKKVOmsGGDZgIREenNsE3Soo115NFEc5aSNEme3nq8tsW2jkt2wAEHdBp77Fe/+hUPPvggACtWrGDp0qVbJWlTpkxh+vTpAOy3334sX758q+2uWrWK888/n9WrV9Pc3NyxjyeeeIJ77rmno15JSQl/+9vfOOKIIzrqlJaW9vs4RETSybC9J61mYw0L23amPlcD2YoUFBR0vK+oqOCJJ57g2Wef5dVXX2XGjBndjk2Wk5PT8T4jI4PW1tat6lxyySVcdNFFvP766/z+97/v2I67bzWcRnfLRESkZ8M2Sau2Yk5t/QErSg5Jdigig6qoqIja2toeyzdu3EhJSQn5+fm8+eabPPfcc9u8r02bNjF+/HgAbrvtto7ls2fP5je/+U3H5+rqag4++GD+/e9/89577wHocqeISB+GbZI2dXQRS38wh/3GZCQ7FJFBVVZWxqGHHsqee+7JJZdcslX5scceS2trK3vvvTdXXHEFBx100Dbv6/LLL+fTn/40hx9+OOXlWwaN/u53v0t1dTV77rkn++yzD/Pnz2fUqFHcfPPNnHLKKeyzzz6cfvrp27xfEZF0MGzvSQOIRIyMiC6vSPq56667On2eNWtWx/ucnBweffTRbtdrv++svLycN954o2P5xRdf3G39448/njPOOGOr5YWFhZ161trNmTOHOXPm9BW+iIgwjHvSRERERIYyJWkiIiIiKUhJmoiIiEgKUpImIiIikoKUpImIiIikICVpIiIiIilISZrIMFNTU8Nvf/vbbV7/F7/4BQ0NDQMYkYiIbAslaSLDjJI0EZHhYVgPZiuSEv50/NbL9jgJDrgAmhvgzk9vXT79MzDjLKivgnvP6VicF22F8x/vdXeXXXYZ77zzDtOnT+eYY47h+uuv5/rrr+fee++lqamJk08+me9973vU19dz2mmnUVlZSTQa5YorrmDNmjWsWrWKj370o5SXlzN//vxO277mmmv429/+xubNmznkkEP46U9/CsCyZcv40pe+xLp168jIyOC+++5j55135rrrruP2228nEokwZ84crr322v6fPxGRNKUkTWSYufbaa3njjTdYuHAhAPPmzWPp0qW88MILuDsnnHACTz31FOvWrWPcuHH84x//AII5PYuLi/nZz37G/PnzO03z1O6iiy7iyiuvBOCzn/0sjz32GKeddhpnnXUWl112GSeffDKNjY20tbXx6KOP8tBDD/H888+Tn5+vuTpFRPpJSZpIop33j57LsvN7Ly8o61S+ubaWon7uft68ecybN48ZM2YAUFdXx9KlSzn88MO5+OKLufTSS/nEJz7B4Ycf3ue25s+fz3XXXUdDQwMbNmxg6tSp1NbWsnLlSk4++WQAcnNzAXjiiSc477zzyM/PB6C0tLSfkYuIpDclaSLDnLtz+eWX88UvfnGrspdeeom5c+dy+eWXM3v27I5esu40Njby5S9/mQULFjBx4kSuvvpqGhsbcfce92umuXNFRLaVHhwQGWaKioqora3t+Pzxj3+cW265hbq6OgBWrlzJ2rVrWbVqFfn5+Zx99tlcfPHFvPzyy92u366xsREIJl+vq6vj/vvvB2DEiBFMmDCBhx56CICmpiYaGhqYPXs2t9xyS8dDCLrcKSLSP+pJExlmysrKOPTQQ9lzzz2ZM2cO119/PUuWLOHggw8GoLCwkDvuuINly5ZxySWXEIlEyMrK4qabbgLgwgsvZM6cOeywww6dHhwYOXIkF1xwAXvttReTJ09m//337yi7/fbb+eIXv8iVV15JVlYW9913H8ceeywLFy5k5syZZGdnc9xxx/GjH/1ocE+GiMgQZj1dqkhVM2fO9AULFsRdv6KiglmzZiUuoH5SPL0bDvEsWbKE3XffPSHx1NbWUlTU37vSEicR8XR3/szsJXefOaA7SoL+tl8iMvRtT/uly50iIiIiKUhJmoiIiEgKUpImkgBD7TaCVKHzJiKyhZI0kQGWm5tLVVWVEo5+cneqqqo6xlkTEUl3erpTZIBNmDCByspK1q1bN+DbbmxsTKkkZqDjyc3NZcKECQO2PRGRoUxJmsgAy8rKYsqUKQnZdkVFRcfMAakg1eIRERlOEnq508yONbO3zGyZmV3WTXmOmf0lLH/ezCYnMh4RkXip/RKRZEtYkmZmGcCNwBxgGnCmmU3rUu0LQLW7TwV+DvwkUfGIiMRL7ZeIpIJE9qQdACxz93fdvRm4BzixS50TgdvC9/cDR5km+xOR5FP7JSJJl8h70sYDK2I+VwIH9lTH3VvNbCNQBqyPrWRmFwIXhh/rzOytfsRR3nV7SaZ4eqd4epeu8ew4CPuIlaj2q8nM3khIxIMv1b6L20PHknqGy3EA7LatKyYySevuL8quYxLEUwd3vxm4eZuCMFuQStPJKJ7eKZ7eKZ5Bk5D2azidLx1LahouxzJcjgOCY9nWdRN5ubMSmBjzeQKwqqc6ZpYJFAMbEhiTiEg81H6JSNIlMkl7EdjFzKaYWTZwBvBIlzqPAOeG7z8F/Ms1AqiIJJ/aLxFJuoRd7gzv0bgIeBzIAG5x90Vmdg2wwN0fAf4PuN3MlhH8BXpGAkLZpsukCaR4eqd4eqd4BkEC26/hdL50LKlpuBzLcDkO2I5jMf3hJyIiIpJ6NHeniIiISApSkiYiIiKSgoZFkpZK07eY2UQzm29mS8xskZl9vZs6s8xso5ktDF9XJiqemH0uN7PXw/1t9TiwBX4VnqPXzGzfBMayW8yxLzSzTWb2jS51EnqOzOwWM1sbO2aVmZWa2T/NbGn4s6SHdc8N6yw1s3O7qzNA8VxvZm+Gv48HzWxkD+v2+rsdwHiuNrOVMb+T43pYt9d/j+kgldqk7RXHsfyvmS0Ov6dPmtlgj2kXt3i/m2b2KTNzM0vJISDiOQ4zOy38vSwys7sGO8Z4xfH9mhT+n/pK+B3rtt1Jtu7azC7l2/Z/rLsP6RfBTb3vADsB2cCrwLQudb4M/C58fwbwlwTGswOwb/i+CHi7m3hmAX8f5PO0HCjvpfw44FGCsZ8OAp4fxN/fh8COg3mOgCOAfYE3YpZdB1wWvr8M+Ek365UC74Y/S8L3JQmKZzaQGb7/SXfxxPO7HcB4rgYujuP32eu/x+H+SrU2aRCO5aNAfvj+f4bysYT1ioCngOeAmcmOext/J7sAr7S3TcDoZMe9HcdyM/A/4ftpwPJkx93DsWzVZnYp36b/Y4dDT1pKTd/i7qvd/eXwfS2whGBk8lR3IvBnDzwHjDSzHQZhv0cB77j7+4Owrw7u/hRbj2kV+z25DTipm1U/DvzT3Te4ezXwT+DYRMTj7vPcvTX8+BzBWF2DoofzE494/j0OdynVJm2nPo/F3ee7e0P4cVC/p/0U73fz+wR/sDUOZnD9EM9xXADcGLZRuPvaQY4xXvEciwMjwvfFbD1eYUqIo83cpv9jh0OS1t30LV2Tok7TtwDt07ckVHgJYwbwfDfFB5vZq2b2qJntkehYCL7o88zsJQumqekqnvOYCGcAd/dQNtjnaIy7r4Yg2QZGd1MnWefp8wR/hXWnr9/tQLoo7Kq/pYfLwck6P6kkZdukbdDf3+cX6Pl7mmx9HouZzQAmuvvfBzOwfornd7IrsKuZPWNmz5nZdv8hmSDxHMvVwNlmVgnMBb46OKENuG1qG4dDkjZg07cMJDMrBB4AvuHum7oUv0xweW8f4NfAQ4mMJXSou+8LzAG+YmZHdClPxjnKBk4A7uumOBnnKB7JOE/fAVqBO3uo0tfvdqDcBOwMTAdWAzd0U2fQz08KSsk2aRvFHaeZnQ3MBK5PaETbrtdjMbMI8HPgW4MW0baJ53eSSXDJcxZwJvDHnu5pTbJ4juVM4FZ3n0BwyfD28Hc11GzTv/mheKBdpdz0LWaWRZCg3enuf+1a7u6b3L0ufD8XyDKz8kTFE+5nVfhzLfAgQTdzrHjO40CbA7zs7mu6FiTjHAFr2rufw5/dXSIY1PMUPpjwCeAsD29s6CqO3+2AcPc17h519zbgDz3sJxnfo1STcm3Sdojr92lmRwPfAU5w96ZBiq2/+jqWImBPoMLMlhPcN/RICj48EO/362F3b3H394C3CJK2VBPPsXwBuBfA3Z8FcgkmXx9qtqltHA5JWkpN3xLeV/J/wBJ3/1kPdca2339iZgcQ/B6qEhFPuI8CMytqf09wQ3rXJ1AeAc4Jn0A5CNjYfukvgc6kh0udg32OQrHfk3OBh7up8zgw28xKwst9s8NlAy68RHEpwX98DT3Uied3O1DxxN4/cXIP+4nn3+Nwl1Jt0nbq81jCS4S/J/iepuq9T9DHsbj7Rncvd/fJ7j6Z4P66E9x9QJ6YHkDxfL8eInigg/CP210JHnJKNfEcywcE9y5jZrsTJGnrBjXKgbFt/8cOxlMPiX4RdIG+TfCUyHfCZdcQ/AOD4Jd6H7AMeAHYKYGxHEbQhfkasDB8HQd8CfhSWOciYBHBkyzPAYck+PzsFO7r1XC/7ecoNiYDbgzP4esk+KkmIJ8g6SqOWTZo54ggOVwNtBD8hfMFgnuCngSWhj9Lw7ozgT/GrPv58Lu0DDgvgfEsI7iHof171P404Dhgbm+/2wTFc3v43XiNoMHZoWs84eet/j2m2yuV2qRBOJYngDUx39NHkh3zth5Ll7oViW4HE/g7MeBnwOLw3+wZyY55O45lGvBM2MYtBGYnO+YejqO7NnO7/4/VtFAiIiIiKWg4XO4UERERGXaUpImIiIikICVpIiIiIilISZqIiIhIClKSJiIiIpKClKTJkGdms8wsladxERER6TclaSIiIiIpSEmaDBozO9vMXjCzhWb2ezPLMLM6M7vBzF42syfNbFRYd3o4MfBrZvZg+2TeZjbVzJ4IJ15/2cx2DjdfaGb3m9mbZnZnzGwF15rZ4nA7P03SoYuIiPSbkjQZFOF0HqcTTAY+HYgCZwEFBPN37gv8G7gqXOXPwKXuvjfB6Mzty+8EbvRg4vVDCEZ4BpgBfINgdOqdgEPNrJRg+qI9wu38ILFHKSIiMnCUpMlgOQrYD3jRzBaGn3cC2oC/hHXuAA4zs2JgpLv/O1x+G3BEOEfleHd/EMDdG33LnJYvuHulB5N/LwQmA5uARuCPZnYK0O38lyIiIqlISZoMFgNuc/fp4Ws3d7+6m3q9zVNmvZQ1xbyPApnu3gocADwAnAQ81s+YRUREkkZJmgyWJ4FPmdloADMrNbMdCb6DnwrrfAb4j7tvBKrN7PBw+WeBf7v7JqDSzE4Kt5FjZvk97dDMCgkmcJ9LcCl0eiIOTEREJBEykx2ApAd3X2xm3wXmmVkEaAG+AtQDe5jZS8BGgvvWAM4FfhcmYe8C54XLPwv83syuCbfx6V52WwQ8bGa5BL1w3xzgwxIREUkYc+/t6pJIYplZnbsXJjsOERGRVKPLnSIiIiIpSD1pIiIiIilIPWkiIiIiKUhJmoiIiEgKUpImIiIikoKUpImIiIikICVpIiIiIino/wODdixCH9xOcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b1f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title('hidden size = 50\\ntotaltime:56.5s, acu:0,.9781')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"hiddensize5\")\n",
    "plt.grid(True)\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x, train_acc_list2, label='train acc')\n",
    "plt.plot(x, test_acc_list2, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title('hidden size = 50\\ntotal:51.5, acu:0.9683')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"hiddensize50\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
